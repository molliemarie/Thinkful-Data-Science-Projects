{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Thinkful Data Science Course\n",
    "##Unit 4: Predicting the Future; Lesson 1: Making Predictions\n",
    "##Metrics and Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Take the loan data you used previously to build your linear regression model.\n",
    "\n",
    "2) Break the data-set into 10 segments following the example provided here in KFold (http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators).\n",
    "\n",
    "3) Compute each of the performance metric (MAE, MSE or R2) for all the folds. The average would be the performance of your model.\n",
    "\n",
    "4) Comment on each of the performance metric you obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1) Take the loan data you used previously to build your linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Import data\n",
    "loansData = pd.read_csv('https://spark-public.s3.amazonaws.com/dataanalysis/loansData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into numbers - will return in form [###, ###]\n",
    "cleanFICORange = loansData['FICO.Range'].map(lambda x: x.split('-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We have a string inside a list. Need to convert each string to integer\n",
    "# To do this, we use a list comprehension\n",
    "# We could either choose the first element, last element, or an average value\n",
    "# The \"[0]\" at the end makes it so that we only choose the first element\n",
    "cleanFICOScore = cleanFICORange.map(lambda x: [int(n) for n in x][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# According to Thinkful, to understand better, check out: http://carlgroner.me/Python/2011/11/09/An-Introduction-to-List-Comprehensions-in-Python.html\n",
    "\n",
    "# Assign cleaned score to new column called \"FICO.Score\"\n",
    "loansData['FICO.Score'] = cleanFICOScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CLEAN INTEREST RATE DATA\n",
    "clean_ir = loansData[\"Interest.Rate\"].map(lambda x: round(float(x.rstrip(\"%\"))/100, 4))\n",
    "loansData[\"Interest.Rate\"] = clean_ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CLEAN LOAN LENGTH DATA\n",
    "clean_loanLength = loansData[\"Loan.Length\"].map(lambda x: float(x.rstrip(\"months\")))\n",
    "loansData[\"Loan.Length\"] = clean_loanLength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear regression model: \n",
    "# InterestRate = b + a1(FICOScore) + a2(LoanAmount)\n",
    "\n",
    "intrate = loansData['Interest.Rate']\n",
    "loanamt = loansData['Amount.Requested']\n",
    "fico = loansData['FICO.Score']\n",
    "\n",
    "# Create y and x variables\n",
    "# The dependent variable\n",
    "y = np.matrix(intrate).transpose()\n",
    "# The independent variables shaped as columns\n",
    "x1 = np.matrix(fico).transpose()\n",
    "x2 = np.matrix(loanamt).transpose()\n",
    "# put the two columns together to create an input matrix \n",
    "x = np.column_stack([x1,x2])\n",
    "\n",
    "# Create linear model\n",
    "X = sm.add_constant(x)\n",
    "model = sm.OLS(y,X)\n",
    "f = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coeff = f.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot:\n",
    "line=[]\n",
    "line2 = []\n",
    "for j in fico:\n",
    "\tline.append(coeff[0] + coeff[1]*j + coeff[2]*10000)\n",
    "\tline2.append(coeff[0] + coeff[1]*j + coeff[2]*30000)\n",
    "\n",
    "plt.close()\n",
    "plt.scatter(fico,intrate)\n",
    "plt.hold(True)\n",
    "plt.plot(fico, line, label = '$10,000 Requested', color = 'blue')\n",
    "plt.plot(fico, line2, label = '$30,000 Requested', color = 'green')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.ylabel('Interest Rate in %')\n",
    "plt.xlabel('FICO Score')\n",
    "plt.savefig('Fico_Scatter_10000&30000.png')\n",
    "\n",
    "# Load to new CSV file\n",
    "# loansData.to_csv('loansData_clean.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2) Break the data-set into 10 segments following the example provided here in KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model, cross_validation, grid_search\n",
    "kf = cross_validation.KFold(len(fico), n_folds=10)\n",
    "r2 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3) Compute each of the performance metric (MAE, MSE or R2) for all the folds. The average would be the performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "print y_test will give a matrix and not an array, but y_predict is an array not a matrix. Should put them in the same format. Used np.squeeze to convert matrix to an array.\n",
    "\n",
    "fitted y=mx, not y=mx+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 250  251  252 ..., 2497 2498 2499] TEST: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2250 is out of bounds for axis 0 with size 2250",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3dccee411579>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TRAIN:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TEST:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2250 is out of bounds for axis 0 with size 2250"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf:\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = sm.OLS(y_train, X_train)\n",
    "#     X = sm.add_constant(X_train)\n",
    "#     model = sm.OLS(y_train, X)\n",
    "    f=model.fit()\n",
    "    y_pred = f.predict(X_test)\n",
    "    print('y_pred is:', y_pred)\n",
    "    r2.append(r2_score(np.squeeze(np.asarray(y_test)),y_pred))\n",
    "\n",
    "#     mse = mean_squared_error(y_test, y_train)\n",
    "#     mae = mean_absolute_error(y_test, y_train)\n",
    "#     r2 = r2_score(y_test, y_train)\n",
    "    \n",
    "    \n",
    "# >>> from sklearn.metrics import r2_score\n",
    "# >>> y_true = [3, -0.5, 2, 7]\n",
    "# >>> y_pred = [2.5, 0.0, 2, 8]\n",
    "# >>> r2_score(y_true, y_pred)  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of K-Fold from https://www.quantstart.com/articles/Using-Cross-Validation-to-Optimise-a-Machine-Learning-Method-The-Regression-Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_fold_cross_val_poly(folds, degrees, X, y):\n",
    "    n = len(X)\n",
    "    kf = KFold(n, n_folds=folds)\n",
    "    kf_dict = dict([(\"fold_%s\" % i,[]) for i in range(1, folds+1)])\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf:\n",
    "        fold += 1\n",
    "        print \"Fold: %s\" % fold\n",
    "        X_train, X_test = X.ix[train_index], X.ix[test_index]\n",
    "        y_train, y_test = y.ix[train_index], y.ix[test_index]\n",
    "        # Increase degree of linear regression polynomial order\n",
    "        for d in range(1, degrees+1):\n",
    "            print \"Degree: %s\" % d\n",
    "            # Create the model and fit it\n",
    "            polynomial_features = PolynomialFeatures(\n",
    "                degree=d, include_bias=False\n",
    "            )\n",
    "            linear_regression = LinearRegression()\n",
    "            model = Pipeline([\n",
    "                (\"polynomial_features\", polynomial_features),\n",
    "                (\"linear_regression\", linear_regression)\n",
    "            ])\n",
    "            model.fit(X_train, y_train)\n",
    "            # Calculate the test MSE and append to the\n",
    "            # dictionary of all test curves\n",
    "            y_pred = model.predict(X_test)\n",
    "            test_mse = mean_squared_error(y_test, y_pred)\n",
    "            kf_dict[\"fold_%s\" % fold].append(test_mse)\n",
    "        # Convert these lists into numpy arrays to perform averaging\n",
    "        kf_dict[\"fold_%s\" % fold] = np.array(kf_dict[\"fold_%s\" % fold])\n",
    "    # Create the \"average test MSE\" series by averaging the \n",
    "    # test MSE for each degree of the linear regression model,\n",
    "    # across each of the k folds.\n",
    "    kf_dict[\"avg\"] = np.zeros(degrees)\n",
    "    for i in range(1, folds+1):\n",
    "        kf_dict[\"avg\"] += kf_dict[\"fold_%s\" % i]\n",
    "    kf_dict[\"avg\"] /= float(folds)\n",
    "    return kf_dict\n",
    ".."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###4) Comment on each of the performance metric you obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
