{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Thinkful Data Science Course\n",
    "##Unit 4: Predicting the Future; \n",
    "##Lesson 8: Evaluating Classifier Performance\n",
    "\n",
    "Throughout the unit we've been splitting our data into training, test, and validation sets. Let's take a moment and discuss why this is necesary. By now you can probably see that learning an estimator and testing that estimator's performance on the same data is a methodological mistake. It's like if a professor administered a test with the exact same questions as the practice test. All a student would have to do to get 100% would be to memorize all the solutions to the practice test; they wouldn't acutally have to learn anything. If you test your estimator on the data used to train it, it knows all the answers, and thus can achieve a perfect score, even though it very well could fail to predict any- thing on data it's never seen before. This is called overfitting. Predicting on never-before-seen data is kind of the whole point, so knowing how our estimator performs on data its already seen isn't really useful.\n",
    "\n",
    "Holding out a subset of your data for testing, i.e., excluding a subset of your data from your training set, gives you some never-before-seen data to test your estimator's performance. The scikit-learn library has a train_test_split helper function to randomly split data into training and test sets.\n",
    "\n",
    "When evaluating different settings (“hyperparameters”) for estimators, such as the C setting that must be manually set for an SVM, there is still a risk of overfitting on the test set because the parameters can be tweaked until the estimator performs optimally. This way, knowledge about the test set can “leak” into the model and we can't make claims about how it will generalize (i.e., how it will perform) on never-before-seen data.\n",
    "\n",
    "To resolve this problem, we can hold out yet another subset of our data for validation. Training proceeds on the training set, evaluation is done on the validation set, and when it seems like we have a good model, we can perform our final evaluation on the test set.\n",
    "\n",
    "####Use the cross_validation.train_test_split() helper function to split the Iris dataset into training and test sets, holding out 40% of the data for testing. \n",
    "How many points do you have in your training set? In your test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris_df = pd.DataFrame()\n",
    "iris_df['sepal_length'] = iris.data[:,0]\n",
    "iris_df['sepal_width'] = iris.data[:,1]\n",
    "iris_df['petal_length'] = iris.data[:,2]\n",
    "iris_df['petal_width'] = iris.data[:,3]\n",
    "iris_df['target'] = iris.target\n",
    "iris_df['target_flower'] = iris.target\n",
    "iris_df['target_flower'].replace(0, 'setosa', inplace = True)\n",
    "iris_df['target_flower'].replace(1, 'versicolor', inplace = True)\n",
    "iris_df['target_flower'].replace(2, 'virginica', inplace = True)\n",
    "iris_df1 = iris_df[iris_df['target_flower']=='setosa']\n",
    "iris_df2 = iris_df[iris_df['target_flower']=='versicolor']\n",
    "iris_df3 = iris_df[iris_df['target_flower']=='virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = iris_df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].as_matrix()\n",
    "y = iris_df['target'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.4,  2.7,  5.3,  1.9],\n",
       "       [ 6.3,  2.9,  5.6,  1.8],\n",
       "       [ 6.5,  3. ,  5.2,  2. ],\n",
       "       [ 6.3,  3.3,  6. ,  2.5],\n",
       "       [ 5.8,  2.6,  4. ,  1.2],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 6.7,  3. ,  5. ,  1.7],\n",
       "       [ 6.9,  3.1,  5.1,  2.3],\n",
       "       [ 4.9,  2.4,  3.3,  1. ],\n",
       "       [ 6. ,  3.4,  4.5,  1.6],\n",
       "       [ 5.6,  2.7,  4.2,  1.3],\n",
       "       [ 6.5,  3.2,  5.1,  2. ],\n",
       "       [ 6.3,  2.5,  5. ,  1.9],\n",
       "       [ 6.9,  3.2,  5.7,  2.3],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 6. ,  2.9,  4.5,  1.5],\n",
       "       [ 7.4,  2.8,  6.1,  1.9],\n",
       "       [ 7.2,  3. ,  5.8,  1.6],\n",
       "       [ 6.3,  2.8,  5.1,  1.5],\n",
       "       [ 7.2,  3.6,  6.1,  2.5],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 6. ,  2.2,  5. ,  1.5],\n",
       "       [ 5.8,  2.7,  3.9,  1.2],\n",
       "       [ 5.1,  3.7,  1.5,  0.4],\n",
       "       [ 4.8,  3. ,  1.4,  0.3],\n",
       "       [ 5.1,  3.8,  1.9,  0.4],\n",
       "       [ 6.7,  3.1,  4.7,  1.5],\n",
       "       [ 5.9,  3. ,  4.2,  1.5],\n",
       "       [ 5. ,  3. ,  1.6,  0.2],\n",
       "       [ 4.8,  3. ,  1.4,  0.1],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.5,  1.3,  0.3],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 5. ,  2.3,  3.3,  1. ],\n",
       "       [ 7.7,  2.6,  6.9,  2.3],\n",
       "       [ 6.7,  3. ,  5.2,  2.3],\n",
       "       [ 4.5,  2.3,  1.3,  0.3],\n",
       "       [ 5.9,  3.2,  4.8,  1.8],\n",
       "       [ 6.7,  3.3,  5.7,  2.5],\n",
       "       [ 6.4,  3.2,  5.3,  2.3],\n",
       "       [ 5.5,  2.4,  3.7,  1. ],\n",
       "       [ 5. ,  2. ,  3.5,  1. ],\n",
       "       [ 5.4,  3.9,  1.3,  0.4],\n",
       "       [ 6.2,  2.2,  4.5,  1.5],\n",
       "       [ 4.8,  3.4,  1.9,  0.2],\n",
       "       [ 5.2,  3.5,  1.5,  0.2],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 4.4,  3.2,  1.3,  0.2],\n",
       "       [ 5.2,  2.7,  3.9,  1.4],\n",
       "       [ 5.7,  3.8,  1.7,  0.3],\n",
       "       [ 6.1,  2.6,  5.6,  1.4],\n",
       "       [ 4.3,  3. ,  1.1,  0.1],\n",
       "       [ 5.7,  3. ,  4.2,  1.2],\n",
       "       [ 6.5,  3. ,  5.8,  2.2],\n",
       "       [ 5.6,  3. ,  4.1,  1.3],\n",
       "       [ 4.7,  3.2,  1.6,  0.2],\n",
       "       [ 6.8,  2.8,  4.8,  1.4],\n",
       "       [ 5.5,  2.6,  4.4,  1.2],\n",
       "       [ 6. ,  2.2,  4. ,  1. ],\n",
       "       [ 6.3,  3.4,  5.6,  2.4],\n",
       "       [ 5. ,  3.5,  1.6,  0.6],\n",
       "       [ 6.4,  2.8,  5.6,  2.2],\n",
       "       [ 7.7,  3. ,  6.1,  2.3],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 5.7,  2.8,  4.1,  1.3],\n",
       "       [ 6.4,  3.2,  4.5,  1.5],\n",
       "       [ 6. ,  3. ,  4.8,  1.8],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 5.7,  2.9,  4.2,  1.3],\n",
       "       [ 6.1,  2.8,  4.7,  1.2],\n",
       "       [ 7.9,  3.8,  6.4,  2. ],\n",
       "       [ 5.2,  3.4,  1.4,  0.2],\n",
       "       [ 5.6,  2.8,  4.9,  2. ],\n",
       "       [ 6.8,  3. ,  5.5,  2.1],\n",
       "       [ 5.8,  4. ,  1.2,  0.2],\n",
       "       [ 7.3,  2.9,  6.3,  1.8],\n",
       "       [ 6.4,  3.1,  5.5,  1.8],\n",
       "       [ 5.7,  2.8,  4.5,  1.3],\n",
       "       [ 7.7,  2.8,  6.7,  2. ],\n",
       "       [ 6.4,  2.8,  5.6,  2.1],\n",
       "       [ 6.2,  3.4,  5.4,  2.3],\n",
       "       [ 5.7,  2.5,  5. ,  2. ],\n",
       "       [ 5.2,  4.1,  1.5,  0.1],\n",
       "       [ 5.5,  2.4,  3.8,  1.1],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 5.5,  2.3,  4. ,  1.3],\n",
       "       [ 6.3,  2.5,  4.9,  1.5]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.7,  3.1,  4.4,  1.4],\n",
       "       [ 6.8,  3.2,  5.9,  2.3],\n",
       "       [ 6.1,  3. ,  4.9,  1.8],\n",
       "       [ 5.1,  3.5,  1.4,  0.3],\n",
       "       [ 7. ,  3.2,  4.7,  1.4],\n",
       "       [ 5.1,  3.4,  1.5,  0.2],\n",
       "       [ 5.4,  3.4,  1.5,  0.4],\n",
       "       [ 5.6,  2.5,  3.9,  1.1],\n",
       "       [ 5. ,  3.4,  1.6,  0.4],\n",
       "       [ 5.8,  2.8,  5.1,  2.4],\n",
       "       [ 5.5,  3.5,  1.3,  0.2],\n",
       "       [ 7.2,  3.2,  6. ,  1.8],\n",
       "       [ 5.5,  2.5,  4. ,  1.3],\n",
       "       [ 6.3,  2.7,  4.9,  1.8],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5. ,  3.2,  1.2,  0.2],\n",
       "       [ 5.1,  2.5,  3. ,  1.1],\n",
       "       [ 5.6,  2.9,  3.6,  1.3],\n",
       "       [ 6.6,  3. ,  4.4,  1.4],\n",
       "       [ 6.4,  2.9,  4.3,  1.3],\n",
       "       [ 4.9,  2.5,  4.5,  1.7],\n",
       "       [ 6.3,  2.3,  4.4,  1.3],\n",
       "       [ 5.1,  3.8,  1.6,  0.2],\n",
       "       [ 7.7,  3.8,  6.7,  2.2],\n",
       "       [ 6.7,  3.3,  5.7,  2.1],\n",
       "       [ 4.6,  3.2,  1.4,  0.2],\n",
       "       [ 6.1,  2.9,  4.7,  1.4],\n",
       "       [ 4.8,  3.4,  1.6,  0.2],\n",
       "       [ 5.6,  3. ,  4.5,  1.5],\n",
       "       [ 5.9,  3. ,  5.1,  1.8],\n",
       "       [ 5.4,  3.4,  1.7,  0.2],\n",
       "       [ 5.4,  3.7,  1.5,  0.2],\n",
       "       [ 6. ,  2.7,  5.1,  1.6],\n",
       "       [ 5. ,  3.3,  1.4,  0.2],\n",
       "       [ 4.6,  3.6,  1. ,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.5,  4.2,  1.4,  0.2],\n",
       "       [ 6.1,  3. ,  4.6,  1.4],\n",
       "       [ 6.5,  2.8,  4.6,  1.5],\n",
       "       [ 6.9,  3.1,  5.4,  2.1],\n",
       "       [ 7.6,  3. ,  6.6,  2.1],\n",
       "       [ 6.1,  2.8,  4. ,  1.3],\n",
       "       [ 5.7,  4.4,  1.5,  0.4],\n",
       "       [ 5.1,  3.3,  1.7,  0.5],\n",
       "       [ 6.7,  2.5,  5.8,  1.8],\n",
       "       [ 6.7,  3.1,  5.6,  2.4],\n",
       "       [ 6.9,  3.1,  4.9,  1.5],\n",
       "       [ 4.4,  3. ,  1.3,  0.2],\n",
       "       [ 7.1,  3. ,  5.9,  2.1],\n",
       "       [ 6.5,  3. ,  5.5,  1.8],\n",
       "       [ 6.2,  2.9,  4.3,  1.3],\n",
       "       [ 5.4,  3. ,  4.5,  1.5],\n",
       "       [ 6.3,  3.3,  4.7,  1.6],\n",
       "       [ 5.1,  3.8,  1.5,  0.3],\n",
       "       [ 6.2,  2.8,  4.8,  1.8],\n",
       "       [ 4.8,  3.1,  1.6,  0.2],\n",
       "       [ 5.8,  2.7,  4.1,  1. ],\n",
       "       [ 5.3,  3.7,  1.5,  0.2],\n",
       "       [ 6.6,  2.9,  4.6,  1.3],\n",
       "       [ 5.7,  2.6,  3.5,  1. ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 1, 2, 0, 1, 2, 1, 1, 1, 2, 2, 2, 0, 1, 2, 2, 2, 2, 0, 2,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 2, 2, 0, 1, 2, 2, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 2, 0, 1, 2, 1, 0, 1, 1, 1, 2, 0, 2, 2, 0, 0, 1, 1, 2,\n",
       "       2, 1, 1, 2, 0, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 0, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 0, 1, 0, 0, 1, 0, 2, 0, 2, 1, 2, 0, 0, 1, 1, 1, 1, 2, 1, 0,\n",
       "       2, 2, 0, 1, 0, 1, 2, 0, 0, 1, 0, 0, 0, 0, 1, 1, 2, 2, 1, 0, 0, 2, 2,\n",
       "       1, 0, 2, 2, 1, 1, 1, 0, 2, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####How many points do you have in your training set? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  90 points in the training set\n"
     ]
    }
   ],
   "source": [
    "print('There are ', len(X_train), 'points in the training set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####In your test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60 points in the test set, which is 40.0 % of the data.\n"
     ]
    }
   ],
   "source": [
    "print('There are', len(X_test), 'points in the test set, which is', (len(X_test)/(len(X_test)+len(X_train)))*100, '% of the data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Fit a linear Support Vector Classifier to the training set and evaluate its performance on the test set. \n",
    "\n",
    "What is the score? How does it compare to the score in the Support Vector Machine lesson?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.SVC(kernel='linear')\n",
    "from sklearn import datasets\n",
    "X=X_train\n",
    "y=y_train\n",
    "svc.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####What is the score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####How does it compare to the score in the Support Vector Machine lesson?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
